<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Click-Describe: Multimodal Grounding and Tracking.">
  <meta name="keywords" content="Multimodal Tracking, Aerial Tracking, Grounding">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Click-Describe: Multimodal Grounding and Tracking</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
<!-- 
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Click-Describe: Multimodal Grounding and Tracking.</h1>
          <h3 class="is-size-5 has-text-weight-bold" style="color: orange;">
            Accepted to NeurIPS 2024 Video-Language Modelling Workshop!
          </h3>
          <h3 class="is-size-5 has-text-weight-bold" style="color: orange;">
            Accepted to WACV 2025!
          </h3>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sites.google.com/view/rupanjali-kukal/home">Rupanjali Kukal</a>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/patravali">Jay Patravali</a>,</span>
            <span class="author-block">
              <a href="">Fuxun Yu</a>,
            </span>
            <span class="author-block">
              <a href="">Simranjit Singh</a>,
            </span>
            <span class="author-block">
              <a href="">Nikoloas</a>,
            </span>
            <span class="author-block">
              <a href="">Rishi Madhok</a>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup></sup>Microsoft</span>
            <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openaccess.thecvf.com/content/WACV2025/papers/Kukal_ClickDescribe_Multimodal_Grounding_and_Tracking_for_Aerial_Objects_WACV_2025_paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link.
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/uavdark135/group9_1_compress.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/dtb70/gull1_compress.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/uavtrack112/football1_3_compress.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/uavdt/S0302_compress.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/dtb70/basketball_compress.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/uavdark135/group9_1_compress.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/uav123/car4_compress.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/dtb70/bmx2_compress.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>The fusion of multiple modalities, such as vision and
            language, has led to significant progress in grounding and
            tracking tasks. However, this success has not yet translated to aerial single-object tracking (SOT) due to the lack
            of text annotations in existing aerial SOT datasets. To
            overcome this limitation, we provide text annotations for
            five existing aerial datasets, designed to support and promote multi-modal research in the aerial tracking domain.
            Furthermore, to address challenges such as small object
            dimensions, similar-looking objects, and target size fluctuations, we introduce a third input modality: click (or
            point prompt). We seamlessly integrate click and language
            information in the modelâ€™s input to offer a user-friendly
            and interactive alternative to precise bounding box annotations. This enables approximate target specification with
            reduced effort and time. We introduce CLaVi, a novel multimodal framework that redefines input interaction by incorporating multiple modalities. This integration improves
            target localization and tracking efficiency, providing a significant advancement in the way input is provided to the
            model. Furthermore, we conduct experiments on the five
            datasets, to provide AerTrack-460 benchmark, to validate
            the effectiveness of our approach. AerTrack-460 benchmark shows competitive performance and, in some cases,
            outperforms previous language-based grounding and tracking techniques, setting a strong baseline for future research.
            Code and data will be made available soon</p>

        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Animation. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-height">
        <h2 class="title is-3">AerTrack-460 Dataset</h2>

        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Interpolating states</h3> -->
        <div class="content has-text-justified">
          <p>
            To extend the applicability of vision-language trackers to the aerial domain, we develop AerTrack-460, which is a collection of official videos and annotations from five diverse aerial datasets, including UAVDT, UAV123, UAVDark135, DTB70, and UAVTrack112.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <!-- <img src="./dataset/1.pdf"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/> -->
            <iframe src="./dataset/6.pdf"></iframe>
            <p>Start Frame</p>
          </div>
          <div class="column is-3 has-text-centered">
            <!-- <img src="./dataset/1.pdf"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/> -->
            <iframe src="./dataset/2.pdf"></iframe>
            <p>Start Frame</p>
          </div>
          <div class="column is-3 has-text-centered">
            <!-- <img src="./dataset/1.pdf"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/> -->
            <iframe src="./dataset/3.pdf"></iframe>
            <p>Start Frame</p>
          </div>
          <div class="column is-3 has-text-centered">
            <!-- <img src="./dataset/1.pdf"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/> -->
            <iframe src="./dataset/4.pdf"></iframe>
            <p>Start Frame</p>
          </div>
        </div>
        <br/>
      </div>
    </div>
    <!--/ Animation. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Clavi. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-height">
        <h2 class="title is-centered">CLaVi Architecture</h2>

        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Interpolating states</h3> -->
        <div class="content has-text-justified">
          <img src="./dataset/clavi.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
        </div>
        <div class="content has-text-justified">
          <p>
            CLaVi Overview: (a) We first encode the input image, language prompt, and click prompt through individual encoders and a
unified feature fusion encoder; (b) Different memory module design are adopted to process and enhance three type of semantics: natural
language semantics, click trajectory semantics, and vision appearance semantics; (c) We finally use a transformer-based unified localization
decoder to ingest fused information and predict the target object bounding boxes.

          </p>
        </div>
        </div>
        <br/>
      </div>
    </div>
    <!--/ Animation. -->
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{Kukal_2025_WACV,
      author    = {Kukal, Rupanjali and Patravali, Jay and Yu, Fuxun and Singh, Simranjit and Karianakis, Nikolaos and Madhok, Rishi},
      title     = {Click\&Describe: Multimodal Grounding and Tracking for Aerial Objects},
      booktitle = {Proceedings of the Winter Conference on Applications of Computer Vision (WACV)},
      month     = {February},
      year      = {2025},
      pages     = {6011-6021}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            If you use the source code of this website <a
            href="https://github.com/RupanjaliKukal/Click-Describe-Multimodal-Grounding-and-Tracking-for-Aerial-Objects.git">source code</a>, please also link back  <a
              href="https://github.com/nerfies/nerfies.github.io"> Nerfies source code</a> in your footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
